Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                            count
---------------------------  -------
all                                1
load_query_distribution            1
load_reference_distribution        1
subsample_query                    1
total                              4

Select jobs to execute...

[Fri Nov  1 12:41:19 2024]
rule load_query_distribution:
    input: shuf.a.bed.gz
    output: query_distribution.txt
    jobid: 2
    reason: Missing output files: query_distribution.txt; Code has changed since last execution
    resources: tmpdir=/tmp

[Fri Nov  1 12:41:46 2024]
Error in rule load_query_distribution:
    jobid: 2
    input: shuf.a.bed.gz
    output: query_distribution.txt
    shell:
        
        zcat shuf.a.bed.gz | awk '{print $3 - $2}' | sort | uniq -c |         awk '{print $2, $1}' |         awk '{total += $2} END {for (i = 1; i <= NR; i++) print $1[i], $2[i], $2[i]/total}' > query_distribution.txt
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job load_query_distribution since they might be corrupted:
query_distribution.txt
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-11-01T124118.297651.snakemake.log
